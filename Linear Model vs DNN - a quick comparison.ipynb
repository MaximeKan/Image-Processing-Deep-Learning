{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick comparison between a Linear Classifier and a Deep Neural Network\n",
    "\n",
    "## MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code aims to briefly highlight what benefits a DNN can bring in terms of accuracy for an image classifier. This is done using the usual MNIST dataset on Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us load and reshape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will build a linear model for this. A linear model is nothing else than a neural network without any hidden layers. Hence, we can build it using the Keras Sequential tools.\n",
    "\n",
    "We choose to keep 20% of the data for validation, and train it on 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 2s 39us/step - loss: 0.5102 - acc: 0.8686 - val_loss: 0.3167 - val_acc: 0.9139\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.3179 - acc: 0.9117 - val_loss: 0.2861 - val_acc: 0.9214\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.2933 - acc: 0.9183 - val_loss: 0.2745 - val_acc: 0.9233\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.2818 - acc: 0.9208 - val_loss: 0.2738 - val_acc: 0.9217\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.2734 - acc: 0.9233 - val_loss: 0.2644 - val_acc: 0.9263\n",
      "10000/10000 [==============================] - 0s 14us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2709509532779455, 0.9246]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, validation_split = 0.2)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This linear model has an accuracy of 0.93 on the validation sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we move on to a Deep Neural Network, that has two hidden layers. We use the activation function relu, that usually works well, and a 20% Dropout to avoid overfitting.\n",
    "\n",
    "We still use 20% of the sample for validation, and 5 epochs for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 11s 235us/step - loss: 0.2361 - acc: 0.9282 - val_loss: 0.1286 - val_acc: 0.9620\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 10s 207us/step - loss: 0.1119 - acc: 0.9654 - val_loss: 0.1137 - val_acc: 0.9665\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 10s 207us/step - loss: 0.0833 - acc: 0.9742 - val_loss: 0.0925 - val_acc: 0.9728\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 10s 206us/step - loss: 0.0672 - acc: 0.9801 - val_loss: 0.0752 - val_acc: 0.9787\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 10s 212us/step - loss: 0.0590 - acc: 0.9813 - val_loss: 0.0847 - val_acc: 0.9760\n",
      "10000/10000 [==============================] - 0s 44us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07859076420282073, 0.977]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, validation_split = 0.2)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This deep NN has an accuracy of 0.98 on the validation sample, which is similar to the accuracy of the training sample (0.98), which indicates there is very little overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "Adding hidden layers to our linear model is a good way of increasing accuracy without overfitting. This example shows why it is interesting to use Deep Learning to improve classification in image analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_2_starter.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
